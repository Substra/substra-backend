## @section Global Substra settings
## @param settings The settings to use for substra (`prod` or `dev`)
##
settings: prod
## @param config The configuration to use for substra
##
config: {}
## @param organizationName Current organization name
##
organizationName: owkin
## @param DataSampleStorageInServerMedia If set to true, Datasamples which are registered by a "path" are kept on the "servermedias" volume. If set to `false` (default value), the datasample will be duplicated to MinIO.
##
DataSampleStorageInServerMedia: false

privateCa:
  ## @param privateCa.enabled Run the init container injecting the private CA certificate
  ##
  enabled: false
  ## @param privateCa.image.repository Private CA injector image
  ## @param privateCa.image.tag Private CA injector tag
  ## @param privateCa.image.pullPolicy Private CA injector pull policy
  ## @param privateCa.image.pullSecrets Specify image pull secrets
  ## @param privateCa.image.registry The registry to pull the CA Cert Injector image
  ##
  image:
    registry: ghcr.io
    repository: substra/substra-backend-ca-cert-injector
    tag: null
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be created manually in the namespace.
    ##
    pullSecrets: []
  ## @param privateCa.secret.name Name of the _Secret_ containing the private CA certificate
  ## @param privateCa.secret.data Certificate to add in the _Secret_
  ## @param privateCa.secret.fileName Certificate filename in the _Secret_
  secret:
    name: substra-private-ca
    data:
    fileName: private-ca.crt


## @section Server settings
## @param server.replicaCount Number of server replicas
## @param server.defaultDomain The hostname and port of the backend. This address will be used as the assets `storage_address` field
## @param server.subpath The subpath under which the API is served
## @param server.commonHostDomain The common host under which the backend and frontend are served
## @param server.uwsgiProcesses The number of uwsgi processes
## @param server.uwsgiThreads The number of uwsgi threads
## @param server.allowImplicitLogin Allow clients to get API tokens directly with username+password on the `/api-token-auth/` endpoint (ie `Client.login` in the Substra SDK)
## @param server.allowLocalRequests Allow calls to the backend API from within the cluster and local addresses (for instance when multiple organization are in the same cluster, or using a cluster on your machine)
##
server:
  replicaCount: 1
  defaultDomain: localhost
  subpath: ""
  commonHostDomain: ""
  uwsgiProcesses: 20
  uwsgiThreads: 10
  allowImplicitLogin: true
  allowLocalRequests: false

  ## Substra backend image version
  ## @param server.image.registry Substra backend server image registry
  ## @param server.image.repository Substra backend server image repository
  ## @param server.image.tag Substra backend server image tag (defaults to AppVersion)
  ## @param server.image.pullPolicy Substra backend server image pull policy
  ## @param server.image.pullSecrets Specify image pull secrets
  ##
  image:
    registry: ghcr.io
    repository: substra/substra-backend
    tag: null
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be created manually in the namespace.
    ##
    pullSecrets: []

  ## @param server.podSecurityContext.enabled Enable security context
  ## @param server.podSecurityContext.runAsUser User ID for the pod
  ## @param server.podSecurityContext.runAsGroup Group ID for the pod
  ## @param server.podSecurityContext.fsGroup FileSystem group ID for the pod
  ##
  podSecurityContext:
    enabled: true
    runAsUser: 1001
    runAsGroup: 1001
    fsGroup: 1001

  service:
    ## @param server.service.type Kubernetes Service type
    ##
    type: ClusterIP
    ## @param server.service.port Server port
    ##
    port: 8000
    ## @param server.service.clusterIP _ClusterIP_ or `None` for headless service
    ## e.g:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param server.service.loadBalancerIP Load balancer IP if service type is `LoadBalancer`
    ##
    loadBalancerIP: ""
    ## @param server.service.loadBalancerSourceRanges Addresses that are allowed when service is `LoadBalancer`
    ## e.g:
    ## - 10.1O.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param server.service.nodePort Specify the `nodePort` value for the `LoadBalancer` and `NodePort` service types
    ##
    nodePort: ""
    ## @param server.service.externalIPs A list of IP addresses for which nodes in the cluster will also accept traffic for this service
    ##
    externalIPs: []
    ## @param server.service.annotations Additional annotations for the _Service_ resource.
    ##
    annotations: {}

  ingress:
    ## @param server.ingress.enabled Deploy an ingress for the substra backend server
    ##
    enabled: false

    ## @param server.ingress.hostname Default host for the ingress resource
    ##
    hostname: substra.backend.local

    ## @param server.ingress.pathType Ingress path type
    ##
    pathType: ImplementationSpecific

    ## @param server.ingress.path Path for the default host
    ##
    path: /

    ## @param server.ingress.extraPaths The list of extra paths to be created for the default host
    ## e.g:
    ## extraPaths:
    ##   - path: /
    ##     pathType: ImplementationSpecific
    ##     backend:
    ##       service:
    ##         name: substra-backend-svc
    ##         port:
    ##           name: http
    ##
    extraPaths: []

    ## @param server.ingress.annotations Additional annotations for the Ingress resource.
    ##
    annotations: {}

    ## @param server.ingress.extraHosts The list of additional hostnames to be covered with this ingress record
    ## e.g:
    ## extraHosts:
    ##   - name: chart-example.local
    ##     path: /
    ##     pathType: ImplementationSpecific
    ##
    extraHosts: []

    ## @param server.ingress.extraTls The tls configuration for hostnames to be coverred by the ingress
    ## e.g:
    ## extraTls:
    ##   - hosts:
    ##       - chart-example.local
    ##     secretName: substra-tls
    ##
    extraTls: []

    ## @param server.ingress.ingressClassName _IngressClass_ that will be used to implement the Ingress
    ##
    ingressClassName:

  ## @param server.nodeSelector Node labels for pod assignment
  ##
  nodeSelector: {}
  ## @param server.tolerations Toleration labels for pod assignment
  ##
  tolerations: []
  ## @param server.affinity Affinity settings for pod assignment
  ##
  affinity: {}
  ## @param server.resources.requests.cpu Server container cpu request
  ## @param server.resources.requests.memory Server container memory request
  ## @param server.resources.limits.cpu Server container cpu limit
  ## @param server.resources.limits.memory Server container memory limit
  ##
  resources:
    requests:
      cpu: "1000m"
      memory: "6Gi"
    limits:
      cpu: "2000m"
      memory: "12Gi"


  persistence:
    ## @param server.persistence.storageClass Specify the _StorageClass_ used to provision the volume. Or the default _StorageClass_ will be used. Set it to `-` to disable dynamic provisioning
    ##
    storageClass: ""
    ## @param server.persistence.servermedias.size Servermedias volume size
    ## @param server.persistence.servermedias.existingClaim use this PVC rather than creating a new one
    ##
    servermedias:
      size: 10Gi
      existingClaim: null
  ## server containers' liveness probe
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
  ## @param server.livenessProbe.enabled Enable livenessProbe
  ## @param server.livenessProbe.path Path of the HTTP service for checking the healthy state
  ## @param server.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param server.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param server.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param server.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param server.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    path: /liveness
    initialDelaySeconds: 60
    periodSeconds: 45
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1
  ## server containers' readiness probe
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
  ## @param server.readinessProbe.enabled Enable readinessProbe
  ## @param server.readinessProbe.path Path of the HTTP service for checking the healthy state
  ## @param server.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param server.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param server.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param server.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param server.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    path: /readiness
    initialDelaySeconds: 5
    periodSeconds: 30
    timeoutSeconds: 2
    failureThreshold: 3
    successThreshold: 1

  metrics:
    ## @param server.metrics.enabled Start a prometheus exporter
    ##
    enabled: false
    ## Metrics exporter image version
    ## @param server.metrics.image.registry Substra backend server Prometheus Exporter image registry
    ## @param server.metrics.image.repository Substra backend server Prometheus Exporter image repository
    ## @param server.metrics.image.tag Substra backend server Prometheus Exporter image tag (defaults to AppVersion)
    ## @param server.metrics.image.pullPolicy Substra backend server Prometheus Exporter image pull policy
    ##
    image:
      registry: ghcr.io
      repository: substra/substra-backend-metrics-exporter
      tag: null
      pullPolicy: IfNotPresent

    serviceMonitor:
      ## @param server.metrics.serviceMonitor.enabled Create ServiceMonitor resource for scraping metrics using Prometheus Operator
      ##
      enabled: false
      ## @param server.metrics.serviceMonitor.namespace Namespace for the ServiceMonitor resource (defaults to the Release Namespace)
      ##
      namespace: ""
      ## @param server.metrics.serviceMonitor.interval Interval at which metrics should be scraped
      ##
      interval: ""
      ## @param server.metrics.serviceMonitor.scrapeTimeout Timeout after which the scrape is ended
      ##
      scrapeTimeout: ""
      ## @param server.metrics.serviceMonitor.relabelings RelabelConfigs to apply to samples before scraping
      ##
      relabelings: []
      ## @param server.metrics.serviceMonitor.metricRelabelings MetricRelabelConfigs to apply to samples before insertion
      ##
      metricRelabelings: []
      ## @param server.metrics.serviceMonitor.honorLabels Specify honorLabels parameter of the scrape endpoint
      ##
      honorLabels: false

## @section Substra worker settings
##
worker:
  ## @param worker.enabled Enable worker service
  ##
  enabled: true
  ## @param worker.replicaCount Replica count for the worker service
  ##
  replicaCount: 1
  ## @param worker.concurrency Maximum amount of tasks to process in parallel
  ##
  concurrency: 1
  ## @param worker.image.registry Substra backend worker image registry
  ## @param worker.image.repository Substra backend worker image repository
  ## @param worker.image.tag Substra backend worker image tag (defaults to AppVersion)
  ## @param worker.image.pullPolicy Substra backend worker image pull policy
  ## @param worker.image.pullSecrets Specify image pull secrets
  ##
  image:
    registry: ghcr.io
    repository: substra/substra-backend
    tag: null
    pullPolicy: IfNotPresent
    pullSecrets: []
  ## @param worker.podSecurityContext.enabled Enable security context
  ## @param worker.podSecurityContext.runAsUser User ID for the pod
  ## @param worker.podSecurityContext.runAsGroup Group ID for the pod
  ## @param worker.podSecurityContext.fsGroup FileSystem group ID for the pod
  ##
  podSecurityContext:
    enabled: true
    runAsUser: 1001
    runAsGroup: 1001
    fsGroup: 1001
  ## @param worker.resources.requests.cpu Worker container cpu request
  ## @param worker.resources.requests.memory Worker container memory request
  ## @param worker.resources.limits.cpu Worker container cpu limit
  ## @param worker.resources.limits.memory Worker container memory limit
  ##
  resources:
    requests:
      cpu: "1000m"
      memory: "4Gi"
    limits:
      cpu: "2000m"
      memory: "8Gi"
  ## @param worker.nodeSelector Node labels for pod assignment
  ##
  nodeSelector: {}
  ## @param worker.tolerations Toleration labels for pod assignment
  ##
  tolerations: []
  ## @param worker.affinity Affinity settings for pod assignment, ignored if `DataSampleStorageInServerMedia` is `true`
  ##
  affinity: {}
  ## @param worker.rbac.create Create a role for the worker
  ##
  rbac:
    create: true
  serviceAccount:
    ## @param worker.serviceAccount.create Create a service account for the worker
    ##
    create: true
    ## @param worker.serviceAccount.name The name of the ServiceAccount to use. If not set and create is true, a name is generated using the substra.fullname template
    ##
    name: ""
  ## @param worker.persistence.storageClass Specify the _StorageClass_ used to provision the volume. Or the default _StorageClass_ will be used. Set it to `-` to disable dynamic provisioning
  ## @param worker.persistence.size The size of the volume. The size of this volume should be sufficient to store many assets.
  ##
  persistence:
    storageClass: ""
    size: 10Gi
  computePod:
    ## @param worker.computePod.maxStartupWaitSeconds Set the maximum amount of time we will wait for the compute pod to be ready
    maxStartupWaitSeconds: 300
    ## @param worker.computePod.securityContext.fsGroup Set the filesystem group for the Compute pod
    ## @param worker.computePod.securityContext.runAsUser Set the user for the Compute pod
    ## @param worker.computePod.securityContext.runAsGroup Set the group for the Compute pod
    ##
    securityContext:
      fsGroup: 1001
      runAsUser: 1001
      runAsGroup: 1001
    ## @param worker.computePod.resources.requests.cpu Worker compute pod container cpu request
    ## @param worker.computePod.resources.requests.memory Worker compute pod container memory request
    ## @param worker.computePod.resources.limits.memory Worker compute pod container memory limit
    ##
    resources:
      requests:
        cpu: "1000m"
        memory: "1Gi"
      limits:
        memory: "64Gi"
    ## @param worker.computePod.nodeSelector Node labels for pod assignment
    ##
    nodeSelector: {}
    ## @param worker.computePod.tolerations Toleration labels for pod assignment
    ##
    tolerations: []
    ## @param worker.computePod.affinity Worker compute pod container affinity. Pass as a string in order to catch the generated pod name on the statefuset environment variable PODNAME.
    ##
    affinity:
      podAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
          matchExpressions:
          - key: statefulset.kubernetes.io/pod-name
            operator: In
            values:
            - $(POD_NAME)
          topologyKey: kubernetes.io/hostname
  events:
    ## @param worker.events.enabled Enable event service
    ##
    enabled: true
    ## @param worker.events.image.registry Substra event app image registry
    ## @param worker.events.image.repository Substra event app image repository
    ## @param worker.events.image.tag Substra event app image tag (defaults to AppVersion)
    ## @param worker.events.image.pullPolicy Substra event app image pull policy
    ## @param worker.events.image.pullSecrets Specify image pull secrets
    ##
    image:
      registry: ghcr.io
      repository: substra/substra-backend
      tag: null
      pullPolicy: IfNotPresent
      pullSecrets: []
    ## @param worker.events.resources.requests.cpu Worker events container cpu request
    ## @param worker.events.resources.requests.memory Worker events container memory request
    ## @param worker.events.resources.limits.cpu Worker events container cpu limit
    ## @param worker.events.resources.limits.memory Worker events container memory limit
    ##
    resources:
      requests:
        memory: "200Mi"
        cpu: "500m"
      limits:
        memory: "400Mi"
        cpu: "500m"
    ## @param worker.events.podSecurityContext.enabled Enable security context
    ## @param worker.events.podSecurityContext.runAsUser User ID for the pod
    ## @param worker.events.podSecurityContext.runAsGroup Group ID for the pod
    ## @param worker.events.podSecurityContext.fsGroup FileSystem group ID for the pod
    ##
    podSecurityContext:
      enabled: true
      runAsUser: 1001
      runAsGroup: 1001
      fsGroup: 1001
    ## @param worker.events.nodeSelector Node labels for pod assignment
    ##
    nodeSelector: {}
    ## @param worker.events.tolerations Toleration labels for pod assignment
    ##
    tolerations: []
    ## @param worker.events.affinity Affinity settings for pod assignment
    ##
    affinity: {}
    ## @param worker.events.rbac.create Create a role and service account for the event app
    ##
    rbac:
      create: true
    serviceAccount:
      ## @param worker.events.serviceAccount.create Create a service account for the event app
      ##
      create: true
      ## @param worker.events.serviceAccount.name The name of the ServiceAccount to use
      ## If not set and create is true, a name is generated using the substra.fullname template
      ##
      name: ""
  ## @param worker.volumeAccessMode Access mode for volume
  ##
  volumeAccessMode: "ReadWriteOnce"
## @section Substra periodic tasks worker settings
##
schedulerWorker:
  ## @param schedulerWorker.enabled Enable scheduler worker service
  ##
  enabled: true
  ## @param schedulerWorker.replicaCount Replica count for the periodic tasks worker
  ##
  replicaCount: 1
  ## @param schedulerWorker.image.registry Substra backend tasks scheduler image registry
  ## @param schedulerWorker.image.repository Substra backend tasks scheduler image repository
  ## @param schedulerWorker.image.tag Substra backend tasks scheduler image tag (defaults to AppVersion)
  ## @param schedulerWorker.image.pullPolicy Substra backend task scheduler image pull policy
  ## @param schedulerWorker.image.pullSecrets Specify image pull secrets
  ##
  image:
    registry: ghcr.io
    repository: substra/substra-backend
    tag: null
    pullPolicy: IfNotPresent
    pullSecrets: []
  ## @param schedulerWorker.nodeSelector Node labels for pod assignment
  ##
  nodeSelector: {}
  ## @param schedulerWorker.tolerations Toleration labels for pod assignment
  ##
  tolerations: []
  ## @param schedulerWorker.affinity Affinity settings for pod assignment
  ##
  affinity: {}
  ## @param schedulerWorker.resources.requests.cpu Scheduler container cpu request
  ## @param schedulerWorker.resources.requests.memory Scheduler container memory request
  ## @param schedulerWorker.resources.limits.cpu Scheduler container cpu limit
  ## @param schedulerWorker.resources.limits.memory Scheduler container memory limit
  ##
  resources:
    requests:
      cpu: "250m"
      memory: "200Mi"
    limits:
      cpu: "250m"
      memory: "400Mi"
  ## @param schedulerWorker.podSecurityContext.enabled Enable security context
  ## @param schedulerWorker.podSecurityContext.runAsUser User ID for the pod
  ## @param schedulerWorker.podSecurityContext.runAsGroup Group ID for the pod
  ## @param schedulerWorker.podSecurityContext.fsGroup FileSystem group ID for the pod
  ##
  podSecurityContext:
    enabled: true
    runAsUser: 1001
    runAsGroup: 1001
    fsGroup: 1001

## @section Celery task scheduler settings
scheduler:
  ## @param scheduler.enabled Enable scheduler service
  ##
  enabled: true
  ## @param scheduler.replicaCount Replica count for the scheduler server
  ##
  replicaCount: 1
  ## @param scheduler.image.registry Substra backend tasks scheduler image registry
  ## @param scheduler.image.repository Substra backend tasks scheduler image repository
  ## @param scheduler.image.tag Substra backend tasks scheduler image tag (defaults to AppVersion)
  ## @param scheduler.image.pullPolicy Substra backend task scheduler image pull policy
  ## @param scheduler.image.pullSecrets Specify image pull secrets
  ##
  image:
    registry: ghcr.io
    repository: substra/substra-backend
    tag: null
    pullPolicy: IfNotPresent
    pullSecrets: []
  ## @param scheduler.resources.requests.cpu Scheduler container cpu request
  ## @param scheduler.resources.requests.memory Scheduler container memory request
  ## @param scheduler.resources.limits.cpu Scheduler container cpu limit
  ## @param scheduler.resources.limits.memory Scheduler container memory limit
  ##
  resources:
    requests:
      cpu: "250m"
      memory: "200Mi"
    limits:
      cpu: "250m"
      memory: "400Mi"
  ## @param scheduler.nodeSelector Node labels for pod assignment
  ##
  nodeSelector: {}
  ## @param scheduler.tolerations Toleration labels for pod assignment
  ##
  tolerations: []
  ## @param scheduler.affinity Affinity settings for pod assignment
  ##
  affinity: {}
  ## @param scheduler.podSecurityContext.enabled Enable security context
  ## @param scheduler.podSecurityContext.runAsUser User ID for the pod
  ## @param scheduler.podSecurityContext.runAsGroup Group ID for the pod
  ## @param scheduler.podSecurityContext.fsGroup FileSystem group ID for the pod
  ##
  podSecurityContext:
    enabled: true
    runAsUser: 1001
    runAsGroup: 1001
    fsGroup: 1001


## @section Builder settings
## @param builder.replicaCount Number of builder replicas
##
builder:
  ## @param builder.enabled Enable builder service
  ##
  enabled: true
  ## @param builder.replicaCount Replica count for the builder service
  ##
  replicaCount: 1

  ## @param builder.concurrency Maximum amount of tasks to process in parallel
  ##
  concurrency: 1

  ## @param builder.kanikoStartup.maxAttempts Number of checks done before considering a kaniko pod has failed to spawn
  ## @param builder.kanikoStartup.checkDelay Time, in seconds, to wait when a container is in pending state before checking again its status
  ##
  kanikoStartup:
    maxAttempts: 60
    checkDelay: 2

  ## Substra backend image version
  ## @param builder.image.registry Substra backend server image registry
  ## @param builder.image.repository Substra backend server image repository
  ## @param builder.image.tag Substra backend server image tag (defaults to AppVersion)
  ## @param builder.image.pullPolicy Substra backend server image pull policy
  ## @param builder.image.pullSecrets Specify image pull secrets
  ##
  image:
    registry: ghcr.io
    repository: substra/substra-backend
    tag: null
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be created manually in the namespace.
    ##
    pullSecrets: []

  ## @param builder.podSecurityContext.enabled Enable security context
  ## @param builder.podSecurityContext.runAsUser User ID for the pod
  ## @param builder.podSecurityContext.runAsGroup Group ID for the pod
  ## @param builder.podSecurityContext.fsGroup FileSystem group ID for the pod
  ##
  podSecurityContext:
    enabled: true
    runAsUser: 1001
    runAsGroup: 1001
    fsGroup: 1001


  ## @param builder.resources.requests.cpu Builder container cpu request
  ## @param builder.resources.requests.memory Builder container memory request
  ## @param builder.resources.limits.cpu Builder container cpu limit
  ## @param builder.resources.limits.memory Builder container memory limit
  ##
  resources:
    requests:
      cpu: "2000m"
      memory: "4Gi"
    limits:
      cpu: "2000m"
      memory: "8Gi"
  ## @param builder.nodeSelector Node labels for pod assignment
  ##
  nodeSelector: { }
  ## @param builder.tolerations Toleration labels for pod assignment
  ##
  tolerations: [ ]
  ## @param builder.affinity Affinity settings for pod assignment, ignored if `DataSampleStorageInServerMedia` is `true`
  ##
  affinity: { }


  persistence:
    ## @param builder.persistence.storageClass Specify the _StorageClass_ used to provision the volume. Or the default _StorageClass_ will be used. Set it to `-` to disable dynamic provisioning
    ## @param builder.persistence.size The size of the volume.
    ##
    storageClass: ""
    size: 10Gi

  ## @param builder.rbac.create Create a role and service account for the builder
  ##
  rbac:
    create: true
  serviceAccount:
    ## @param builder.serviceAccount.create Create a service account for the builder
    ##
    create: true
    ## @param builder.serviceAccount.name The name of the ServiceAccount to use. If not set and create is true, a name is generated using the substra.fullname template
    ##
    name: ""



## @section Substra container registry settings
##
containerRegistry:
  ## @param containerRegistry.local Whether the registry is exposed as a _nodePort_ and located in the same _Namespace_ as Substra.
  ##
  local: true
  ## @param containerRegistry.host Hostname of the container registry
  ##
  host: 127.0.0.1
  ## @param containerRegistry.port Port of the container registry
  ##
  port: 5000
  ## @param containerRegistry.scheme Communication scheme of the container registry
  ##
  scheme: http
  ## @param containerRegistry.userImageRepository Name of the repository where to push and pull user docker images
  ##
  userImageRepository: substra/user-image
  ## @param containerRegistry.pullDomain Hostname from which the cluster should pull container images
  ##
  pullDomain: 127.0.0.1
  ## @param containerRegistry.prepopulate Images to add to the container registry
  ## e.g:
  ## - image: owkin/substra-tools:0.7.0
  ##   sourceRegistry: ghcr.io
  ##   dstImage: test/substra-tools
  ##   dockerConfigSecretName: docker-config
  ##
  prepopulate: []

## @section Api event app settings
##
api:
  events:
    ## @param api.events.enabled Enable event service
    ##
    enabled: true
    ## @param api.events.image.registry Substra event app image registry
    ## @param api.events.image.repository Substra event app image repository
    ## @param api.events.image.tag Substra event app image tag (defaults to AppVersion)
    ## @param api.events.image.pullPolicy Substra event app image pull policy
    ## @param api.events.image.pullSecrets Specify image pull secrets
    ##
    image:
      registry: ghcr.io
      repository: substra/substra-backend
      tag: null
      pullPolicy: IfNotPresent
      pullSecrets: []
    ## @param api.events.resources.requests.cpu Api events container cpu request
    ## @param api.events.resources.requests.memory Api events container memory request
    ## @param api.events.resources.limits.cpu Api events container cpu limit
    ## @param api.events.resources.limits.memory Api events container memory limit
    ##
    resources:
      requests:
        memory: "200Mi"
        cpu: "500m"
      limits:
        memory: "400Mi"
        cpu: "500m"
    ## @param api.events.podSecurityContext.enabled Enable security context
    ## @param api.events.podSecurityContext.runAsUser User ID for the pod
    ## @param api.events.podSecurityContext.runAsGroup Group ID for the pod
    ## @param api.events.podSecurityContext.fsGroup FileSystem group ID for the pod
    ##
    podSecurityContext:
      enabled: true
      runAsUser: 1001
      runAsGroup: 1001
      fsGroup: 1001
    ## @param api.events.nodeSelector Node labels for pod assignment
    ##
    nodeSelector: {}
    ## @param api.events.tolerations Toleration labels for pod assignment
    ##
    tolerations: []
    ## @param api.events.affinity Affinity settings for pod assignment
    ##
    affinity: {}
    ## @param api.events.rbac.create Create a role and service account for the event app
    ##
    rbac:
      create: true
    serviceAccount:
      ## @param api.events.serviceAccount.create Create a service account for the event app
      ##
      create: true
      ## @param api.events.serviceAccount.name The name of the ServiceAccount to use
      ## If not set and create is true, a name is generated using the substra.fullname template
      ##
      name: ""

## @section Orchestrator settings
##
orchestrator:
  ## @param orchestrator.host The orchestrator gRPC endpoint
  ##
  host: orchestrator.local
  ## @param orchestrator.port The orchestrator gRPC port
  ##
  port: 9000
  tls:
    ## @param orchestrator.tls.enabled Enable TLS for the gRPC endpoint
    ##
    enabled: false
    ## @param orchestrator.tls.cacert A configmap containing the orchestrator CA certificate. Use this if your orchestrator uses a private CA.
    ##
    cacert:
    mtls:
      ## @param orchestrator.tls.mtls.enabled Enable client verification for the orchestrator gRPC endpoint
      ##
      enabled: false
      ## @param orchestrator.tls.mtls.clientCertificate A secret containing the client certificate `tls.crt` and private key `tls.key`
      ##
      clientCertificate:
  ## @param orchestrator.mspID current organization name on the Orchestrator
  ##
  mspID: OwkinPeerMSP

  channels:
    ## @param orchestrator.channels[0].mychannel.restricted Make this channel restricted to a single organization. The server will fail if there is more than one instance in this channel
    ## @param orchestrator.channels[0].mychannel.model_export_enabled Allow logged-in users to download models trained on this organization
    ##
    - mychannel:
        restricted: false
        model_export_enabled: false

  ## @param orchestrator.sameCluster Turn this setting to on when the orchestrator is on the same cluster to allow a more relaxed network policy
  sameCluster: false

## @section Kaniko settings
##
kaniko:
  ## @param kaniko.image.registry Kaniko image registry
  ## @param kaniko.image.repository Kaniko image repository
  ## @param kaniko.image.tag Kaniko image tag
  ##
  image:
    registry: gcr.io
    repository: kaniko-project/executor
    tag: v1.8.1
  ## @param kaniko.resources.requests.cpu Kaniko container cpu request
  ## @param kaniko.resources.requests.memory Kaniko container memory request
  ## @param kaniko.resources.limits.memory Kaniko container memory limit
  ##
  resources:
    requests:
      cpu: "1000m"
      memory: "4Gi"
    limits:
      memory: "32Gi"
  ## @param kaniko.mirror If set to `true` pull base images from the local registry.
  ##
  mirror: false
  ## @param kaniko.dockerConfigSecretName A Docker config to use for pulling base images
  ##
  dockerConfigSecretName:
  cache:
    warmer:
      ## @param kaniko.cache.warmer.image.registry Kaniko cache warmer registry
      ## @param kaniko.cache.warmer.image.repository Kaniko cache warmer repository
      ## @param kaniko.cache.warmer.image.tag Kaniko cache warmer image tag
      ##
      image:
        registry: gcr.io
        repository: kaniko-project/warmer
        tag: v1.8.1
      ## @param kaniko.cache.warmer.cachedImages A list of docker images to warmup the Kaniko cache
      ## e.g:
      ## - ghcr.io/substra-314908/substra-tools:0.9.0-minimal
      ##
      cachedImages: []
    ## @param kaniko.cache.persistence.storageClass Specify the _StorageClass_ used to provision the volume. Or the default _StorageClass_ will be used. Set it to `-` to disable dynamic provisioning
    ## @param kaniko.cache.persistence.size The size of the volume.
    ##
    persistence:
      storageClass: ""
      size: 10Gi

## @section Account operator settings
##
addAccountOperator:
  ## @param addAccountOperator.outgoingOrganizations Outgoind organizations credentials for substra backend organization-to-organization communications
  ## e.g:
  ## - name: organizationId
  ##   secret: organizationSecret
  ##
  outgoingOrganizations: []
  ## @param addAccountOperator.incomingOrganizations Incoming organizations credentials for substra backend organization-to-organization communications
  ## e.g:
  ## - name: organizationId
  ##   secret: organizationSecret
  ##
  incomingOrganizations: []
  ## @param addAccountOperator.users A list of administrators users who can log into the substra backend server with admin privileges
  ## e.g:
  ## - name: username
  ##   secret: password
  ##   channel: mychannel
  ##
  users: []

## @section Registry prepopulate
##
registryPrepopulate:
  ## @param registryPrepopulate.waitRegistry.resources.requests.cpu Wait registry container cpu request
  ## @param registryPrepopulate.waitRegistry.resources.requests.memory Wait registry container memory request
  ## @param registryPrepopulate.waitRegistry.resources.limits.memory Wait registry container memory limit
  ##
  waitRegistry:
    resources:
      requests:
        memory: "200Mi"
        cpu: "500m"
      limits:
        memory: "400Mi"
  ## @param registryPrepopulate.pause.resources.requests.cpu Pause container cpu request
  ## @param registryPrepopulate.pause.resources.requests.memory Pause container memory request
  ## @param registryPrepopulate.pause.resources.limits.memory Pause container memory limit
  ##
  pause:
    resources:
      requests:
        memory: "64Mi"
        cpu: "50m"
      limits:
        memory: "128Mi"

## @section Single Sign-On through OpenID Connect

## @descriptionStart Uses the authorization code flow.
##
## By default, `oidc.users.useRefreshToken` is enabled. This makes sure the user still has an account at the identity provider, without damaging user experience.
##
## The way it works is that a OIDC user that spent more than `oidc.users.loginValidityDuration` since their last login must undergo a refresh to keep using their access tokens -- but these refreshes are done in the background if `oidc.users.useRefreshToken` is enabled (otherwise a new manual authorization is necessary). The identity provider must support `offline_access` and configuration discovery.
##
## With this option active, you can set `oidc.users.loginValidityDuration` to low values (minutes).
##
## Else, you must strike a balance: longer durations are more convenient, but risk users having continued access even though their account has been disabled.
##
## @descriptionEnd
oidc:
  ## @param oidc.enabled Whether to enable OIDC authentication
  ##
  enabled: false

  ## @param oidc.clientSecretName The name of a secret containing the keys `OIDC_RP_CLIENT_ID` and `OIDC_RP_CLIENT_SECRET` (client ID and secret, typically issued by the provider)
  clientSecretName: null

  provider:
    ## @param oidc.provider.url The identity provider URL (with scheme).
    url: null
    ## @param oidc.provider.port The identity provider port
    port: 443
    ## @param oidc.provider.displayName The name of the provider as displayed in the interface ("Sign in with X")
    displayName: null
    ## @param oidc.provider.sameCluster Turn this setting to on when the OIDC client is hosted on the same cluster to allow a more relaxed network policy
    sameCluster: false
    # @param oidc.provider.endpoints The endpoints are appended to the given provider domain. If not given, they are read from `/.well-known/openid-configuration` at startup.
    endpoints:
      ## @param oidc.provider.endpoints.authorization Typically https://provider/auth
      authorization: null
      ## @param oidc.provider.endpoints.token Typically https://provider/token
      token: null
      ## @param oidc.provider.endpoints.user Typically https://provider/me
      user: null

    ## @param oidc.provider.jwksUri Typically https://provider/jwks. Only required for public-key-based signing algorithms. If not given, read from `/.well-known/openid-configuration` at startup.
    jwksUri: null

  ## @param oidc.signAlgo Either RS256 or HS256
  signAlgo: RS256
  users:
    ## @param oidc.users.useRefreshToken Attempt to refresh user info in the background.
    useRefreshToken: true
    ## @param oidc.users.loginValidityDuration How long a user account is valid after an OIDC login, in seconds
    loginValidityDuration: 3600
    ## @param oidc.users.channel The channel to assign OIDC users to (mandatory)
    channel: null
    ## @param oidc.users.requireApproval Activate the user approval. A user using the OIDC login for the first time will need approval from an admin. It is not compatible with default channel
    requireApproval: false
    ## @param oidc.users.appendDomain As usernames are assigned based on e-mail address, whether to suffix user names with the email domain (john.doe@example.com would then be `john-doe-example`)
    appendDomain: false

## @section Database connection settings
database:
  auth:
    ## @param database.auth.database what DB to connect to
    database: &psql-database substra
    ## @param database.auth.username what user to connect as
    username: &psql-username postgres
    ## @param database.auth.password what password to use for connecting
    password: &psql-password postgres

    ## @param database.auth.credentialsSecretName An alternative to giving username and password; must have `DATABASE_USERNAME` and `DATABASE_PASSWORD` keys.
    ##
    credentialsSecretName: null

  ## @param database.host Hostname of the database to connect to (defaults to local)
  host: null
  ## @param database.port Port of an external database to connect to
  port: 5432

## @section PostgreSQL settings
## @descriptionStart
## Database included as a subchart used by default.
##
## See Bitnami documentation: https://bitnami.com/stack/postgresql/helm
## @descriptionEnd

postgresql:
  ## @param postgresql.enabled Deploy a PostgreSQL instance along the backend for its use
  ##
  enabled: true
  ## @skip postgresql.auth
  auth:
    enablePostgresUser: false
    username: *psql-username
    password: *psql-password
    database: *psql-database
  ## @skip postgresql.primary
  primary:
    resources:
      requests:
        cpu: "1000m"
        memory: "2Gi"
      limits:
        cpu: "1000m"
        memory: "4Gi"
    podSecurityContext:
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
    containerSecurityContext:
      enabled: true
      runAsUser: 1001
      runAsGroup: 1001
      runAsNonRoot: true
      allowPrivilegeEscalation: false
      capabilities:
        drop: [ "ALL" ]
      seccompProfile:
        type: "RuntimeDefault"

## @skip redis
##
redis:
  enabled: true
  architecture: standalone
  auth:
    password: redis
  master:
    persistence:
      enabled: true
    service:
      ports:
        redis: 6379
    resources:
      requests:
        cpu: "500m"
        memory: "512Mi"
      limits:
        cpu: "500m"
        memory: "1024Mi"
    containerSecurityContext:
      enabled: true
      runAsUser: 1001
      runAsGroup: 1001
      runAsNonRoot: true
      allowPrivilegeEscalation: false
      seccompProfile:
        type: RuntimeDefault
      capabilities:
        drop: [ "ALL" ]
  replica:
    replicaCount: 0
  commonConfiguration: |-
    # Enable AOF https://redis.io/topics/persistence
    appendonly yes
    # Disable RDB persistence since AOF persistence is enabled
    save ""
  pdb:
    create: false

## @skip docker-registry
##
docker-registry:
  enabled: true
  storage: filesystem
  persistence:
    enabled: true
    size: 10Gi
    deleteEnabled: true
  service:
    type: NodePort
  resources:
    requests:
      cpu: "500m"
      memory: "16Gi"
    limits:
      cpu: "500m"
      memory: "64Gi"
  containerSecurityContext:
    enabled: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault

## @skip minio
##
minio:
  enabled: true
  auth:
    rootUser: minio
    rootPassword: minio1234
    ## required for helm upgrade to work well (https://github.com/bitnami/charts/blob/1d7e62b47f525fca5ecdc2f34a4e9fa69f1532f5/bitnami/minio/values.yaml#L106)
    forcePassword: true
    ## required to take into account new access and secret keys
    forceNewKeys: true
  resources:
    requests:
      cpu: "500m"
      memory: "16Gi"
    limits:
      cpu: "1000m"
      memory: "64Gi"
  containerSecurityContext:
    enabled: true
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: [ "ALL" ]
    seccompProfile:
      type: "RuntimeDefault"
  pdb:
    create: false

## @skip localstack
##
localstack:
  enabled: false
  service:
    edgeService:
      nodePort: ""
  resources:
    requests:
      cpu: "500m"
      memory: "16Gi"
    limits:
      cpu: "500m"
      memory: "64Gi"
  environment:
    - name: SERVICES
      value: s3
    - name: DEBUG
      value: "1"
    - name: DATA_DIR
      value: "/tmp/localstack/data"
    - name: PORT_WEB_UI
      value: "8080"
    - name: LAMBDA_EXECUTOR
      value: "local"
    - name: KINESIS_ERROR_PROBABILITY
      value: "0.0"
    - name: DOCKER_HOST
      value: "unix:///var/run/docker.sock"
    - name: AWS_ACCESS_KEY_ID
      value: "helloAws"
    - name: AWS_SECRET_ACCESS_KEY
      value: "mySuperSecureAWSAccessKey1234"

  persistence:
    enabled: true
    accessMode: ReadWriteOnce
    size: 5Gi

## @section Helm hooks
##
hooks:
  ## @param hooks.serviceAccount Service account to use for the helm hooks
  ##
  serviceAccount: ""
  ## @param hooks.deleteWorkerPvc.enabled Enable the deletion of deployed compute pods after the application deletion
  ## @param hooks.deleteWorkerPvc.image.repository Image repository for the hook image
  ## @param hooks.deleteWorkerPvc.image.tag Image tag for the hook image
  ##
  deleteWorkerPvc:
    enabled: False
    image:
      repository: bitnami/kubectl
      tag: latest
  ## @param hooks.deleteComputePods.enabled Enable the deletion of the worker PVCs after the application deletion
  ## @param hooks.deleteComputePods.image.repository Image repository for the hook image
  ## @param hooks.deleteComputePods.image.tag Image tag for the hook image
  ##
  deleteComputePods:
    enabled: False
    image:
      repository: bitnami/kubectl
      tag: latest
